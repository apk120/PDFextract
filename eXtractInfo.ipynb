{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import PyPDF2\n",
    "from PIL import Image \n",
    "import pytesseract\n",
    "from pdf2image import convert_from_path\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def textPytesseract(filename):\n",
    "    \n",
    "    #convert PDF to images\n",
    "    # Store all the pages of the PDF in a variable \n",
    "    pages = convert_from_path(filename, 500) \n",
    "    \n",
    "    image_counter = 1\n",
    "    \n",
    "    for page in pages: \n",
    "  \n",
    "        # Declaring filename for each page of PDF as JPG \n",
    "        # For each page, filename will be: \n",
    "        # PDF page n -> page_n.jpg \n",
    "        filename = \"page_\"+str(image_counter)+\".jpg\"\n",
    "\n",
    "        # Save the image of the page in system \n",
    "        page.save(filename, 'JPEG') \n",
    "\n",
    "        # Increment the counter to update filename \n",
    "        image_counter = image_counter + 1\n",
    "    \n",
    "    #Recognizing text from the images using OCR\n",
    "    filelimit = image_counter-1\n",
    "    text=\"\"\n",
    "    for i in range(1, filelimit + 1): \n",
    "    \n",
    "        # Set filename to recognize text from \n",
    "        # Again, these files will be: \n",
    "        # page_n.jpg \n",
    "        filename = \"page_\"+str(i)+\".jpg\"\n",
    "\n",
    "        # Recognize the text as string in image using pytesserct \n",
    "        text_ = str(((pytesseract.image_to_string(Image.open(filename))))) \n",
    "\n",
    "        # The recognized text is stored in variable text \n",
    "        # Any string processing may be applied on text \n",
    "        # Here, basic formatting has been done: \n",
    "        # In many PDFs, at line ending, if a word can't \n",
    "        # be written fully, a 'hyphen' is added. \n",
    "        # The rest of the word is written in the next line \n",
    "        # To remove this, we replace every '-\\n' to ''. \n",
    "        text_ = text_.replace('-\\n', '')\n",
    "        text += text_\n",
    "    \n",
    "    return text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_phone_numbers(text):\n",
    "    r = re.compile(r'(\\d{3}[-\\.\\s]??\\d{3}[-\\.\\s]??\\d{4}|\\(\\d{3}\\)\\s*\\d{3}[-\\.\\s]??\\d{4}|\\d{3}[-\\.\\s]??\\d{4})')\n",
    "    phone_numbers = r.findall(text)\n",
    "    return [re.sub(r'\\D', '', number) for number in phone_numbers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_email_addresses(text):\n",
    "    r = re.compile(r'[\\w\\.-]+@[\\w\\.-]+')\n",
    "    return r.findall(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ie_preprocess(text):\n",
    "    stop_words = stopwords.words('english')\n",
    "    document = ' '.join([i for i in text.split() if i not in stop_words])\n",
    "    sentences = nltk.sent_tokenize(document)\n",
    "    sentences = [nltk.word_tokenize(sent) for sent in sentences]\n",
    "    sentences = [nltk.pos_tag(sent) for sent in sentences]\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_names(text):\n",
    "    names = []\n",
    "    sentences = ie_preprocess(text)\n",
    "    for tagged_sentence in sentences:\n",
    "        for chunk in nltk.ne_chunk(tagged_sentence):\n",
    "            if type(chunk) == nltk.tree.Tree:\n",
    "                if chunk.label() == 'PERSON':\n",
    "                    names.append(' '.join([c[0] for c in chunk]))\n",
    "    return names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = textPytesseract('aditya bhartia (copy).pdf')\n",
    "phone = extract_phone_numbers(text)\n",
    "email = extract_email_addresses(text)\n",
    "names = extract_names(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['9820929220']\n",
      "['adityabhartia@yahoo.com']\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "print (phone)\n",
    "print (email)\n",
    "print (names)#need to train with Indian Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aditya bhartia\n",
      "\n",
      "g-3, tandon apartment, charat singh colony, andheri (e), mumbai\n",
      "ph: +91 9820929220, e-mail: adityabhartia@yahoo.com\n",
      "\n",
      " \n",
      "\n",
      "professional experience\n",
      "noble group/clear capital, mumbai june 2007 — till date\n",
      "\n",
      "equity research analyst at noble group, a uk-based investment bank specializing in small and mid—cap\n",
      "equities. noble’s clients include some offhe uk ’s top institutional investors such as scottish widows, f idelily,\n",
      "\n",
      "gartmore, aberforth, and l&g.\n",
      "\n",
      "- held joint responsibility with the team leader for analysing the uk support services sector, which\n",
      "encompasses a wide array of business models like equipment rental, accident management, social housing\n",
      "and engineering consultancy.\n",
      "\n",
      "- involved in all stages of equity research, starting with company meetings and developing sophisticated\n",
      "earning models and ending with writing research notes and servicing clients through roadshows, meetings,\n",
      "and ad-hoc projects.\n",
      "\n",
      "- prepared thematic industry notes on the uk rental industry and the engineering consultants market,\n",
      "highlighting key growth drivers, and identifying top sector picks.\n",
      "\n",
      "- authored ﬁve initiation reports, with name duly accorded on their front page.\n",
      "\n",
      "- involved with forensic examination of ﬁnancial statements of accident management and vehicle rental\n",
      "companies, with particular emphasis on their operating and ﬁnancial leverage.\n",
      "\n",
      " \n",
      "\n",
      "irevna research services (subsidiary of s&p), chennai oct 2005 — may 2007\n",
      "\n",
      "oﬁfshore equity research associate responsible for fundamental research of european household and\n",
      "personal care sectorfor a bulge bracket investment-bankingﬁrm\n",
      "\n",
      "- built ﬁnancial models for companies. responsible for populating historical ﬁnancial data, making\n",
      "accounting adjustments, ratio and trend analysis, and preparing forecasts of revenues and proﬁtability.\n",
      "\n",
      "- prepared industry presentations for the companies under coverage universe.\n",
      "\n",
      "- authored first call notes for companies under coverage post quarterly earnings and key catalyst events.\n",
      "\n",
      "apprentice\n",
      "lochan & c0, new delhi apr 2003 — aug 2005\n",
      "p. k, narula & c0, new delhi aug 2002 - mar 2003\n",
      "\n",
      " \n",
      "\n",
      "- conducted internal and statutory audits in different sectors.\n",
      "- finalized accounts, prepared balance sheets, and ﬁled returns of income.\n",
      "\n",
      "education\n",
      "\n",
      "- associate chartered accountant may 2005\n",
      "— cleared ca final examinations with 21st rank on all india basis.\n",
      "\n",
      "— cleared ca foundation examination with l9th rank on all india basis.\n",
      "\n",
      "- bachelor of commerce, shri ram college of commerce, delhi — (76%) 2004\n",
      "— secured 2nd rank in delhi university in b. com (hons) lst year.\n",
      "\n",
      "— awarded ufj foundations and srcc alumni scholarships for academic excellence.\n",
      "\n",
      "- cbse(class xii) mahavir senior model school, delhi — (92%) 2001\n",
      "- topped the school in class xii.\n",
      "— secured lst rank in r. s. asiads 2000 for accountancy in class xi.\n",
      "\n",
      "- cbse (class x) mahavir senior model school, delhi — (89%) 1999\n",
      "\n",
      "activities/personal\n",
      "\n",
      "- appointed head boy of the school.\n",
      ". represented delhi state in xxxxii national school games (under 14 all india cricket tournament) held\n",
      "in guwahati in 1996.\n"
     ]
    }
   ],
   "source": [
    "print (text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "from collections import Counter\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('aditya bhartia', 'PERSON'), ('charat singh colony', 'PERSON'), ('mumbai', 'GPE'), ('june 2007', 'DATE'), ('uk', 'GPE'), ('uk', 'GPE'), ('scottish', 'NORP'), ('l&g', 'ORG'), ('uk', 'GPE'), ('the uk rental industry', 'ORG'), ('s&p', 'ORG'), ('2005', 'DATE'), ('may 2007', 'DATE'), ('european', 'NORP'), ('first', 'ORDINAL'), ('quarterly', 'DATE'), ('lochan & c0', 'ORG'), ('new delhi', 'GPE'), ('2003', 'DATE'), ('2005', 'DATE'), ('p. k', 'PERSON'), ('narula & c0', 'ORG'), ('new delhi', 'GPE'), ('2002', 'DATE'), ('2003', 'DATE'), ('may 2005', 'DATE'), ('21st', 'ORDINAL'), ('india', 'GPE'), ('l9th', 'ORG'), ('india', 'GPE'), ('shri ram college of commerce', 'ORG'), ('delhi', 'GPE'), ('76%', 'PERCENT'), ('2004', 'DATE'), ('2nd', 'ORDINAL'), ('delhi university', 'ORG'), ('lst year', 'PERSON'), ('ufj foundations', 'GPE'), ('srcc alumni', 'PERSON'), ('xii)', 'ORG'), ('delhi', 'GPE'), ('92%', 'PERCENT'), ('xii', 'PERSON'), ('secured lst rank', 'PERSON'), ('r. s. asiads 2000', 'GPE'), ('mahavir', 'ORG'), ('delhi', 'GPE'), ('89%', 'PERCENT'), ('1999', 'DATE'), ('xxxxii national school games', 'ORG'), ('india', 'GPE'), ('1996', 'DATE')]\n"
     ]
    }
   ],
   "source": [
    "print([(X.text, X.label_) for X in doc.ents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l&g\n",
      "the uk rental industry\n",
      "s&p\n",
      "lochan & c0\n",
      "narula & c0\n",
      "l9th\n",
      "shri ram college of commerce\n",
      "delhi university\n",
      "xii)\n",
      "mahavir\n",
      "xxxxii national school games\n"
     ]
    }
   ],
   "source": [
    "for X in doc.ents:\n",
    "    if X.label_ == 'ORG':\n",
    "        print (X.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
