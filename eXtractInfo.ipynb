{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import PyPDF2\n",
    "from PIL import Image \n",
    "import pytesseract\n",
    "from pdf2image import convert_from_path\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def textPytesseract(filename):\n",
    "    \n",
    "    #convert PDF to images\n",
    "    # Store all the pages of the PDF in a variable \n",
    "    pages = convert_from_path(filename, 500) \n",
    "    \n",
    "    image_counter = 1\n",
    "    \n",
    "    for page in pages: \n",
    "  \n",
    "        # Declaring filename for each page of PDF as JPG \n",
    "        # For each page, filename will be: \n",
    "        # PDF page n -> page_n.jpg \n",
    "        filename = \"page_\"+str(image_counter)+\".jpg\"\n",
    "\n",
    "        # Save the image of the page in system \n",
    "        page.save(filename, 'JPEG') \n",
    "\n",
    "        # Increment the counter to update filename \n",
    "        image_counter = image_counter + 1\n",
    "    \n",
    "    #Recognizing text from the images using OCR\n",
    "    filelimit = image_counter-1\n",
    "    text=\"\"\n",
    "    for i in range(1, filelimit + 1): \n",
    "    \n",
    "        # Set filename to recognize text from \n",
    "        # Again, these files will be: \n",
    "        # page_n.jpg \n",
    "        filename = \"page_\"+str(i)+\".jpg\"\n",
    "\n",
    "        # Recognize the text as string in image using pytesserct \n",
    "        text_ = str(((pytesseract.image_to_string(Image.open(filename))))) \n",
    "\n",
    "        # The recognized text is stored in variable text \n",
    "        # Any string processing may be applied on text \n",
    "        # Here, basic formatting has been done: \n",
    "        # In many PDFs, at line ending, if a word can't \n",
    "        # be written fully, a 'hyphen' is added. \n",
    "        # The rest of the word is written in the next line \n",
    "        # To remove this, we replace every '-\\n' to ''. \n",
    "        text_ = text_.replace('-\\n', '')\n",
    "        text += text_\n",
    "    \n",
    "    return text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_phone_numbers(text):\n",
    "    r = re.compile(r'(\\d{3}[-\\.\\s]??\\d{3}[-\\.\\s]??\\d{4}|\\(\\d{3}\\)\\s*\\d{3}[-\\.\\s]??\\d{4}|\\d{3}[-\\.\\s]??\\d{4})')\n",
    "    phone_numbers = r.findall(text)\n",
    "    return [re.sub(r'\\D', '', number) for number in phone_numbers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_email_addresses(text):\n",
    "    r = re.compile(r'[\\w\\.-]+@[\\w\\.-]+')\n",
    "    return r.findall(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ie_preprocess(text):\n",
    "    stop_words = stopwords.words('english')\n",
    "    document = ' '.join([i for i in text.split() if i not in stop_words])\n",
    "    sentences = nltk.sent_tokenize(document)\n",
    "    sentences = [nltk.word_tokenize(sent) for sent in sentences]\n",
    "    sentences = [nltk.pos_tag(sent) for sent in sentences]\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_names(text):\n",
    "    names = []\n",
    "    sentences = ie_preprocess(text)\n",
    "    for tagged_sentence in sentences:\n",
    "        for chunk in nltk.ne_chunk(tagged_sentence):\n",
    "            if type(chunk) == nltk.tree.Tree:\n",
    "                if chunk.label() == 'PERSON':\n",
    "                    names.append(' '.join([c[0] for c in chunk]))\n",
    "    return names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = textPytesseract('aditya bhartia (copy).pdf')\n",
    "phone = extract_phone_numbers(text)\n",
    "email = extract_email_addresses(text)\n",
    "names = extract_names(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (phone)\n",
    "print (email)\n",
    "print (names)#need to train with Indian Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "from collections import Counter\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([(X.text, X.label_) for X in doc.ents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for X in doc.ents:\n",
    "    if X.label_ == 'ORG':\n",
    "        print (X.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
